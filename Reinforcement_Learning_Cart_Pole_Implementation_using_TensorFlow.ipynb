{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement Learning Cart-Pole Implementation using TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies"
      ],
      "metadata": {
        "id": "3wVvs9TfVeiz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-X7vombT_Do",
        "outputId": "9333c2ac-76bd-4474-f93c-cfc1ead2c288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.37.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.47.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.47.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.3.0    # TensorFlow is a Python-friendly open source library for numerical computation that makes machine learning and developing neural networks faster and easier        \n",
        "!pip install gym     # Gym is a standard API for reinforcement learning, and a diverse collection of reference environments.\n",
        "!pip install keras   # Keras is an open-source software library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.\n",
        "!pip install keras-rl2   # keras-rl Reinforcement Learning framework like Stable baselines."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update && apt install xvfb && pip3 install pyvirtualdisplay && pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "#To compromise display "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SB2g9oRex8U",
        "outputId": "9efe0efd-2871-420e-fc89-a19401cf3d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 5s (47.4 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "63 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.11).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: piglet in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: piglet-templates in /usr/local/lib/python3.7/dist-packages (from piglet) (1.3.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (3.0.9)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (21.4.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (2.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (0.37.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7ff74ab91050>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Test Random Environment with Open AI Gym"
      ],
      "metadata": {
        "id": "uakKtHP0bRKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym \n",
        "import random"
      ],
      "metadata": {
        "id": "O6GsHbdDZesK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "states = env.observation_space.shape[0]\n",
        "actions = env.action_space.n"
      ],
      "metadata": {
        "id": "1vbDJH_xcEs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Good-general-purpose agents don't need to know the semantics of the observations: they can learn how to map observations to actions to maximize reward without any prior knowledge.\n",
        "# Four-states of CartPole  [position of cart, velocity of cart, angle of pole, rotation rate of pole]\n",
        "print(states)\n",
        "print(actions) # Moving left or right"
      ],
      "metadata": {
        "id": "A1K6fND-cQt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0d2adc-b52f-4a06-c78a-c1774457727e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()                            # At starting of each episode, state is getting reset...\n",
        "    done = False                                   # Here when done = False , episode is not getting completed...\n",
        "    score = 0                                      # Initiate the score as 0 coz which will be added with rewards...\n",
        "    \n",
        "    while not done:                                # while episode is still running i.e No of time steps is not fixed...\n",
        "        env.render()                               # Render the environment\n",
        "        action = random.choice([0,1])              # Choose an action as a random choice\n",
        "\n",
        "        n_state, reward, done, info = env.step(action)    # Get state , reward , done status and info for the action\n",
        "        score+=reward                                     # Add the reward in score\n",
        "    print('Episode:{} Score:{}'.format(episode, score))   # Print final reward for each episode.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6KEqV0DcXty",
        "outputId": "0fdcc25d-6f02-4715-df6a-1bd3df36a40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:13.0\n",
            "Episode:2 Score:23.0\n",
            "Episode:3 Score:19.0\n",
            "Episode:4 Score:24.0\n",
            "Episode:5 Score:16.0\n",
            "Episode:6 Score:20.0\n",
            "Episode:7 Score:16.0\n",
            "Episode:8 Score:11.0\n",
            "Episode:9 Score:14.0\n",
            "Episode:10 Score:23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Create Deep Learning Model with keras"
      ],
      "metadata": {
        "id": "uUwGxRhgC3Hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "fR0lBvL1DBU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(states, actions):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape = (1,states)))\n",
        "  model.add(Dense(24,activation = 'relu'))\n",
        "  model.add(Dense(24,activation = 'relu'))\n",
        "  model.add(Dense(actions,activation = 'linear'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "KUy2aWTKOUim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(states,actions)"
      ],
      "metadata": {
        "id": "zycWE85cQ5pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6l8c1dORMrg",
        "outputId": "73e32d55-4116-482a-f321-351b3f9db5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 24)                120       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 50        \n",
            "=================================================================\n",
            "Total params: 770\n",
            "Trainable params: 770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Agent with keras-RL"
      ],
      "metadata": {
        "id": "PQyWEROORv0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rl.agents import DQNAgent             # Deep Q Network Agent\n",
        "from rl.policy import BoltzmannQPolicy     # Choosing Policy\n",
        "from rl.memory import SequentialMemory     # For replay buffer\n",
        "#Import functionalities from Keras-rl"
      ],
      "metadata": {
        "id": "9EoGEg61RT2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_agent(model,actions):\n",
        "  policy = BoltzmannQPolicy()\n",
        "  memory = SequentialMemory(limit = 50000, window_length=1)       # Agent can store maximum 50000 experience\n",
        "  dqn = DQNAgent(model=model, memory=memory, policy=policy,       \n",
        "                 nb_actions = actions, nb_steps_warmup = 10, target_model_update = 1e-2)  \n",
        "  return dqn\n",
        "\n",
        "#The parameter controls how often the target network is updated. If target_model_update >= 1, the target model is updated every target_model_update-th step. \n",
        "#I.e. if you set target_model_update = 10000, the target model will be updated on step 10 000, 20 000, and so on, \n",
        "#i.e. we set target_model = model on these steps. On the other hand, if target_model_update < 1, we use something called soft updates. \n",
        "#Often times in reinforcement learning the error rate of the first few steps will be very large and may cause your parameters to oscillate. \n",
        "#This is usually attributed to the lack of specificity of the deeper layers in your network. Thus we can come up with some schemes where the learning rate changes in a pre-determined way. \n",
        "#For example we can use constant warm-up or gradual warm-up.\n",
        "#The convergence of stochastic gradient descent is a function of the learning rate and the batch size. When the batch size is increased too much then the needed increase in the learning rate can be such that it is beyond the possible curvature of the loss function.\n",
        "# We thus introduce warm up as a means by which we can introduce large learning rates without the instability.\n"
      ],
      "metadata": {
        "id": "YdkJGVRaXWBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Agent"
      ],
      "metadata": {
        "id": "UABzWGJAArBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = build_agent(model,actions)\n",
        "dqn.compile(Adam(lr=1e-3),metrics=['mae'])\n",
        "dqn.fit(env, nb_steps = 50000, visualize=False, verbose=1)\n",
        "#nb_steps (integer): Number of training steps to be performed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkgWvfjze3Vi",
        "outputId": "839f7a30-17f2-475b-ad90-3278eb570d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "    1/10000 [..............................] - ETA: 7:08 - reward: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000/10000 [==============================] - 73s 7ms/step - reward: 1.0000\n",
            "130 episodes - episode_reward: 76.554 [9.000, 200.000] - loss: 3.463 - mae: 18.889 - mean_q: 38.225\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 74s 7ms/step - reward: 1.0000\n",
            "61 episodes - episode_reward: 161.639 [102.000, 200.000] - loss: 6.791 - mae: 41.019 - mean_q: 82.534\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 75s 8ms/step - reward: 1.0000\n",
            "57 episodes - episode_reward: 176.860 [115.000, 200.000] - loss: 5.132 - mae: 43.019 - mean_q: 86.444\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 77s 8ms/step - reward: 1.0000\n",
            "52 episodes - episode_reward: 191.365 [119.000, 200.000] - loss: 3.927 - mae: 40.041 - mean_q: 80.437\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 77s 8ms/step - reward: 1.0000\n",
            "done, took 376.545 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff6f46d7a90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Agent"
      ],
      "metadata": {
        "id": "O9SlQY5_AuYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = dqn.test(env, nb_episodes=100, visualize = False)\n",
        "print(np.mean(scores.history['episode_reward']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0rUzAYpAwaK",
        "outputId": "97ff0b6f-571d-4b35-da52-95166af94e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 100 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "Episode 21: reward: 200.000, steps: 200\n",
            "Episode 22: reward: 200.000, steps: 200\n",
            "Episode 23: reward: 200.000, steps: 200\n",
            "Episode 24: reward: 200.000, steps: 200\n",
            "Episode 25: reward: 200.000, steps: 200\n",
            "Episode 26: reward: 200.000, steps: 200\n",
            "Episode 27: reward: 200.000, steps: 200\n",
            "Episode 28: reward: 200.000, steps: 200\n",
            "Episode 29: reward: 200.000, steps: 200\n",
            "Episode 30: reward: 200.000, steps: 200\n",
            "Episode 31: reward: 200.000, steps: 200\n",
            "Episode 32: reward: 200.000, steps: 200\n",
            "Episode 33: reward: 200.000, steps: 200\n",
            "Episode 34: reward: 200.000, steps: 200\n",
            "Episode 35: reward: 200.000, steps: 200\n",
            "Episode 36: reward: 200.000, steps: 200\n",
            "Episode 37: reward: 200.000, steps: 200\n",
            "Episode 38: reward: 200.000, steps: 200\n",
            "Episode 39: reward: 200.000, steps: 200\n",
            "Episode 40: reward: 200.000, steps: 200\n",
            "Episode 41: reward: 200.000, steps: 200\n",
            "Episode 42: reward: 200.000, steps: 200\n",
            "Episode 43: reward: 200.000, steps: 200\n",
            "Episode 44: reward: 200.000, steps: 200\n",
            "Episode 45: reward: 200.000, steps: 200\n",
            "Episode 46: reward: 200.000, steps: 200\n",
            "Episode 47: reward: 200.000, steps: 200\n",
            "Episode 48: reward: 200.000, steps: 200\n",
            "Episode 49: reward: 200.000, steps: 200\n",
            "Episode 50: reward: 200.000, steps: 200\n",
            "Episode 51: reward: 200.000, steps: 200\n",
            "Episode 52: reward: 200.000, steps: 200\n",
            "Episode 53: reward: 200.000, steps: 200\n",
            "Episode 54: reward: 200.000, steps: 200\n",
            "Episode 55: reward: 200.000, steps: 200\n",
            "Episode 56: reward: 200.000, steps: 200\n",
            "Episode 57: reward: 200.000, steps: 200\n",
            "Episode 58: reward: 200.000, steps: 200\n",
            "Episode 59: reward: 200.000, steps: 200\n",
            "Episode 60: reward: 200.000, steps: 200\n",
            "Episode 61: reward: 200.000, steps: 200\n",
            "Episode 62: reward: 200.000, steps: 200\n",
            "Episode 63: reward: 200.000, steps: 200\n",
            "Episode 64: reward: 200.000, steps: 200\n",
            "Episode 65: reward: 200.000, steps: 200\n",
            "Episode 66: reward: 200.000, steps: 200\n",
            "Episode 67: reward: 200.000, steps: 200\n",
            "Episode 68: reward: 200.000, steps: 200\n",
            "Episode 69: reward: 200.000, steps: 200\n",
            "Episode 70: reward: 200.000, steps: 200\n",
            "Episode 71: reward: 200.000, steps: 200\n",
            "Episode 72: reward: 200.000, steps: 200\n",
            "Episode 73: reward: 200.000, steps: 200\n",
            "Episode 74: reward: 200.000, steps: 200\n",
            "Episode 75: reward: 200.000, steps: 200\n",
            "Episode 76: reward: 200.000, steps: 200\n",
            "Episode 77: reward: 200.000, steps: 200\n",
            "Episode 78: reward: 200.000, steps: 200\n",
            "Episode 79: reward: 200.000, steps: 200\n",
            "Episode 80: reward: 200.000, steps: 200\n",
            "Episode 81: reward: 200.000, steps: 200\n",
            "Episode 82: reward: 200.000, steps: 200\n",
            "Episode 83: reward: 200.000, steps: 200\n",
            "Episode 84: reward: 200.000, steps: 200\n",
            "Episode 85: reward: 200.000, steps: 200\n",
            "Episode 86: reward: 200.000, steps: 200\n",
            "Episode 87: reward: 200.000, steps: 200\n",
            "Episode 88: reward: 200.000, steps: 200\n",
            "Episode 89: reward: 200.000, steps: 200\n",
            "Episode 90: reward: 200.000, steps: 200\n",
            "Episode 91: reward: 200.000, steps: 200\n",
            "Episode 92: reward: 200.000, steps: 200\n",
            "Episode 93: reward: 200.000, steps: 200\n",
            "Episode 94: reward: 200.000, steps: 200\n",
            "Episode 95: reward: 200.000, steps: 200\n",
            "Episode 96: reward: 200.000, steps: 200\n",
            "Episode 97: reward: 200.000, steps: 200\n",
            "Episode 98: reward: 200.000, steps: 200\n",
            "Episode 99: reward: 200.000, steps: 200\n",
            "Episode 100: reward: 200.000, steps: 200\n",
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.save_weights('dqn_weights.h5f',overwrite=True)"
      ],
      "metadata": {
        "id": "iqZo_ZR2FZlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reloading Agent from Memory"
      ],
      "metadata": {
        "id": "4nVC1fwkF1IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete Existing \n",
        "del model\n",
        "del dqn\n",
        "del env"
      ],
      "metadata": {
        "id": "xxCrP49vF6Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v0')"
      ],
      "metadata": {
        "id": "6OXd8mvNGjez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions = env.action_space.n\n",
        "states = env.observation_space.shape[0]\n",
        "model = build_model(states,actions)\n",
        "dqn = build_agent(model,actions)\n",
        "dqn.compile(Adam(lr=1e-3),metrics=['mae'])"
      ],
      "metadata": {
        "id": "1WBh5mXEGuKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.load_weights('dqn_weights.h5f')"
      ],
      "metadata": {
        "id": "JLoxRlj1Hq9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = dqn.test(env, nb_episodes = 10, visualize = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJuU1nNtH3EC",
        "outputId": "c07e2a6f-f76e-48eb-b905-134b8e0eaa08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n"
          ]
        }
      ]
    }
  ]
}